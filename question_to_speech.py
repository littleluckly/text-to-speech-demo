import os
# å¯¼å…¥å¿…è¦çš„æ¨¡å—
import re              # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—ï¼Œç”¨äºæ–‡æœ¬å¤„ç†
import json            # JSONå¤„ç†æ¨¡å—ï¼Œç”¨äºè¯»å†™JSONæ–‡ä»¶
from pathlib import Path  # è·¯å¾„å¤„ç†æ¨¡å—ï¼Œç”¨äºè·¨å¹³å°æ–‡ä»¶è·¯å¾„æ“ä½œ
import markdown        # Markdownè§£ææ¨¡å—
from bs4 import BeautifulSoup  # HTMLè§£ææ¨¡å—
import edge_tts        # Edge TTSè¯­éŸ³åˆæˆæ¨¡å—
import asyncio         # å¼‚æ­¥ç¼–ç¨‹æ¨¡å—
from typing import Dict, List, Any  # ç±»å‹æç¤ºæ¨¡å—

# å®šä¹‰MarkdownQuestionParserç±»ï¼Œç”¨äºè§£æMarkdownæ–‡ä»¶å¹¶ç”Ÿæˆè¯­éŸ³
class MarkdownQuestionParser:
    # æ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–è§£æå™¨
    # input_file: è¾“å…¥çš„Markdownæ–‡ä»¶è·¯å¾„
    # output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º"questions"
    def __init__(self, input_file: str, output_dir: str = "questions"):
        self.input_file = input_file  # å­˜å‚¨è¾“å…¥æ–‡ä»¶è·¯å¾„
        self.output_dir = Path(output_dir)  # å°†è¾“å‡ºç›®å½•è½¬æ¢ä¸ºPathå¯¹è±¡
        self.voice = "zh-CN-YunyangNeural"  # è®¾ç½®é»˜è®¤è¯­éŸ³ä¸ºä¸­æ–‡ç”·å£°
        
    # æ¸…ç†Markdownæ–‡æœ¬ï¼Œç§»é™¤æ‰€æœ‰æ ¼å¼æ ‡è®°ï¼Œè¿”å›çº¯æ–‡æœ¬
    # text: è¾“å…¥çš„Markdownæ–‡æœ¬
    # è¿”å›: æ¸…ç†åçš„çº¯æ–‡æœ¬
    def clean_markdown_text(self, text: str) -> str:
        """ç§»é™¤Markdownæ ¼å¼å¹¶è¿”å›çº¯æ–‡æœ¬"""
        # ç§»é™¤Markdownæ ‡é¢˜æ ‡è®°ï¼ˆ# åˆ° ######ï¼‰
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤ç²—ä½“å’Œæ–œä½“æ ¼å¼æ ‡è®°
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # ç§»é™¤ç²—ä½“æ ‡è®° (**ç²—ä½“**)
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # ç§»é™¤æ–œä½“æ ‡è®° (*æ–œä½“*)
        text = re.sub(r'__([^_]+)__', r'\1', text)      # ç§»é™¤å¦ä¸€ç§ç²—ä½“æ ‡è®° (__ç²—ä½“__)
        text = re.sub(r'_([^_]+)_', r'\1', text)        # ç§»é™¤å¦ä¸€ç§æ–œä½“æ ‡è®° (_æ–œä½“_)
        
        # ç§»é™¤é“¾æ¥æ ‡è®°ï¼Œä½†ä¿ç•™é“¾æ¥æ–‡æœ¬
        text = re.sub(r'\[([^\]]+)\]\$\$[^)]+\$\$', r'\1', text)
        
        # ç§»é™¤å›¾ç‰‡æ ‡è®°ï¼ˆå®Œå…¨åˆ é™¤ï¼Œä¸ä¿ç•™altæ–‡æœ¬ï¼‰
        text = re.sub(r'!\[([^\]]*)\]\$\$[^)]+\$\$', '', text)
        
        # ç§»é™¤è¡¨æƒ…ç¬¦å·ï¼ˆåŸºæœ¬è¡¨æƒ…ç¬¦å·æ¨¡å¼ï¼‰
        text = re.sub(r'[\U0001F600-\U0001F64F]', '', text)  # ç§»é™¤è¡¨æƒ…ç¬¦å·ï¼ˆç¬‘è„¸ç­‰ï¼‰
        text = re.sub(r'[\U0001F300-\U0001F5FF]', '', text)  # ç§»é™¤ç¬¦å·å’Œè±¡å½¢å›¾
        text = re.sub(r'[\U0001F680-\U0001F6FF]', '', text)  # ç§»é™¤äº¤é€šå’Œåœ°å›¾å›¾æ ‡
        text = re.sub(r'[\U0001F1E0-\U0001F1FF]', '', text)  # ç§»é™¤å›½æ——å›¾æ ‡
        
        # ç§»é™¤ç‰¹æ®Šçš„Markdownç¬¦å·
        text = re.sub(r'[âœ…ğŸ“˜]', '', text)  # ç§»é™¤å¯¹å‹¾å’Œä¹¦æœ¬å›¾æ ‡
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½è¡Œ
        text = re.sub(r'\n\s*\n', '\n\n', text)  # åˆå¹¶å¤šä¸ªç©ºè¡Œä¸ºä¸€ä¸ªç©ºè¡Œ
        text = text.strip()  # ç§»é™¤æ–‡æœ¬ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦
        
        return text
    
    # è§£æYAMLå‰ç½®å…ƒæ•°æ®ï¼ˆfrontmatterï¼‰
    # content: åŒ…å«å‰ç½®å…ƒæ•°æ®çš„æ–‡æœ¬å†…å®¹
    # è¿”å›: åŒ…å«å…ƒæ•°æ®å­—å…¸å’Œå‰©ä½™å†…å®¹çš„å…ƒç»„
    def parse_frontmatter(self, content: str) -> tuple[Dict[str, Any], str]:
        """è§£æYAMLå‰ç½®å…ƒæ•°æ®å¹¶è¿”å›å…ƒæ•°æ®å’Œå‰©ä½™å†…å®¹"""
        # æ”¹è¿›çš„åŒ¹é…YAMLå‰ç½®å…ƒæ•°æ®çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        # åŒ¹é…ä»¥---å¼€å¤´ï¼ˆè¡Œé¦–ï¼‰ï¼Œä¸­é—´æ˜¯YAMLå†…å®¹ï¼Œä»¥---ç»“å°¾ï¼ˆå¯é€‰åœ°åœ¨è¡Œå°¾ï¼‰
        frontmatter_pattern = r'^---\s*\n(.*?)\n---\s*(?:\n|$)'
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å‰ç½®å…ƒæ•°æ®
        match = re.match(frontmatter_pattern, content, re.DOTALL)
        
        if match:
            # æå–å‰ç½®å…ƒæ•°æ®çš„æ–‡æœ¬å†…å®¹
            frontmatter_text = match.group(1)
            # æå–å»é™¤å‰ç½®å…ƒæ•°æ®åçš„å‰©ä½™å†…å®¹
            remaining_content = content[match.end():]
            # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼Œæ˜¾ç¤ºæå–çš„å‰ç½®å…ƒæ•°æ®å†…å®¹
            print(f"\nExtracted frontmatter text (first 100 chars): {frontmatter_text[:100]}...")
            
            # æ‰‹åŠ¨è§£æç±»YAMLæ ¼å¼çš„å‰ç½®å…ƒæ•°æ®
            metadata = {}  # åˆ›å»ºç©ºå­—å…¸å­˜å‚¨å…ƒæ•°æ®
            # é€è¡Œè§£æå‰ç½®å…ƒæ•°æ®
            for line in frontmatter_text.split('\n'):
                line = line.strip()  # å»é™¤æ¯è¡Œä¸¤ç«¯çš„ç©ºç™½
                # æ£€æŸ¥è¡Œæ˜¯å¦åŒ…å«å†’å·ï¼ˆYAMLé”®å€¼å¯¹çš„åˆ†éš”ç¬¦ï¼‰
                if ':' in line and not line.startswith('#'):  # å¿½ç•¥æ³¨é‡Šè¡Œ
                    # åˆ†å‰²é”®å’Œå€¼ï¼Œåªåˆ†å‰²ç¬¬ä¸€ä¸ªå†’å·
                    key, value = line.split(':', 1)
                    key = key.strip()  # å»é™¤é”®ä¸¤ç«¯çš„ç©ºç™½
                    value = value.strip()  # å»é™¤å€¼ä¸¤ç«¯çš„ç©ºç™½
                    
                    # å¤„ç†æ•°ç»„ç±»å‹çš„å€¼ï¼ˆä»¥[å¼€å¤´å¹¶ä»¥]ç»“å°¾ï¼‰
                    if value.startswith('[') and value.endswith(']'):
                        # æå–æ•°ç»„å†…å®¹ï¼ˆå»é™¤æ‹¬å·ï¼‰
                        array_content = value[1:-1]
                        # æŒ‰é€—å·åˆ†å‰²å¹¶å»é™¤æ¯ä¸ªå…ƒç´ çš„ç©ºç™½ï¼Œåˆ›å»ºåˆ—è¡¨
                        metadata[key] = [item.strip() for item in array_content.split(',') if item.strip()]
                    else:
                        # å»é™¤å¼•å·ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                        if value.startswith('"') and value.endswith('"'):
                            value = value[1:-1]
                        elif value.startswith("'") and value.endswith("'"):
                            value = value[1:-1]
                        metadata[key] = value
            
            print(f"Parsed metadata keys: {list(metadata.keys())}")
            return metadata, remaining_content
        else:
            print("No frontmatter pattern matched")
            print(f"Content starts with: {content[:100]}...")
        
        return {}, content
    
    # è§£æå•ä¸ªé—®é¢˜å—
    # block: åŒ…å«å•ä¸ªé—®é¢˜çš„æ–‡æœ¬å—
    # è¿”å›: åŒ…å«é—®é¢˜å…ƒæ•°æ®ã€é¢˜ç›®ã€ç­”æ¡ˆå’Œè§£æçš„å­—å…¸ï¼Œå¦‚æœè§£æå¤±è´¥åˆ™è¿”å›None
    def parse_question_block(self, block: str) -> Dict[str, Any]:
        """è§£æå•ä¸ªé—®é¢˜å—"""
        # è§£æé—®é¢˜å—ä¸­çš„å‰ç½®å…ƒæ•°æ®
        metadata, content = self.parse_frontmatter(block)
        # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼Œæ˜¾ç¤ºè§£æå‡ºçš„å…ƒæ•°æ®
        print(f"Parsed metadata: {metadata}")
        
        # æŸ¥æ‰¾é¢˜ç›®éƒ¨åˆ†
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»¥"## **é¢˜ç›®ï¼š**"å¼€å¤´ï¼Œåˆ°"## **âœ… ç²¾ç®€ç­”æ¡ˆï¼š**"ç»“æŸçš„å†…å®¹
        question_match = re.search(r'## \*\*é¢˜ç›®ï¼š\*\* (.+?)(?=\n## \*\*âœ… ç²¾ç®€ç­”æ¡ˆï¼š\*\*)', content, re.DOTALL)
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¢˜ç›®éƒ¨åˆ†ï¼Œè¿”å›Noneè¡¨ç¤ºè§£æå¤±è´¥
        if not question_match:
            return None
        
        # æå–é¢˜ç›®æ–‡æœ¬å¹¶å»é™¤ä¸¤ç«¯ç©ºç™½
        question_text = question_match.group(1).strip()
        
        # æŸ¥æ‰¾ç²¾ç®€ç­”æ¡ˆéƒ¨åˆ†
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»¥"## **âœ… ç²¾ç®€ç­”æ¡ˆï¼š**"å¼€å¤´ï¼Œåˆ°"**ğŸ“˜ è¯¦ç»†è§£æï¼š**"ç»“æŸçš„å†…å®¹
        # è€ƒè™‘åˆ°"**ğŸ“˜ è¯¦ç»†è§£æï¼š**"å‰é¢å¯èƒ½æœ‰æ¢è¡Œç¬¦ä¹Ÿå¯èƒ½æ²¡æœ‰ï¼Œä½¿ç”¨æ›´çµæ´»çš„æ¨¡å¼
        simple_answer_match = re.search(r'## \*\*âœ… ç²¾ç®€ç­”æ¡ˆï¼š\*\*\s*(.+?)(?=\n?\*\*ğŸ“˜ è¯¦ç»†è§£æï¼š\*\*)', content, re.DOTALL)
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç®€ç­”æ¡ˆéƒ¨åˆ†ï¼Œè¿”å›Noneè¡¨ç¤ºè§£æå¤±è´¥
        if not simple_answer_match:
            return None
        
        # æå–ç²¾ç®€ç­”æ¡ˆæ–‡æœ¬å¹¶å»é™¤ä¸¤ç«¯ç©ºç™½
        simple_answer = simple_answer_match.group(1).strip()
        
        # æŸ¥æ‰¾è¯¦ç»†è§£æéƒ¨åˆ†
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»¥"**ğŸ“˜ è¯¦ç»†è§£æï¼š**"å¼€å¤´çš„å†…å®¹
        # è€ƒè™‘åˆ°è¯¦ç»†è§£æå¯èƒ½æ˜¯æ–‡ä»¶çš„æœ€åéƒ¨åˆ†ï¼Œæˆ–è€…åé¢è·Ÿç€---åˆ†éš”ç¬¦æˆ–å…¶ä»–æ ‡é¢˜
        analysis_match = re.search(r'\*\*ğŸ“˜ è¯¦ç»†è§£æï¼š\*\*\s*(.+?)(?=\n\s*---\s*\n|\n\s*##|\s*$)', content, re.DOTALL)
        # åˆå§‹åŒ–è¯¦ç»†è§£æä¸ºç©ºå­—ç¬¦ä¸²
        detailed_analysis = ""
        # å¦‚æœæ‰¾åˆ°è¯¦ç»†è§£æéƒ¨åˆ†ï¼Œåˆ™æå–å¹¶å»é™¤ä¸¤ç«¯ç©ºç™½
        if analysis_match:
            detailed_analysis = analysis_match.group(1).strip()
        
        # è¿”å›åŒ…å«æ‰€æœ‰è§£æå†…å®¹çš„å­—å…¸
        # æ³¨æ„ï¼šæ‰€æœ‰æ–‡æœ¬å†…å®¹éƒ½é€šè¿‡clean_markdown_textæ–¹æ³•æ¸…ç†äº†Markdownæ ¼å¼
        return {
            'metadata': metadata,  # å…ƒæ•°æ®ä¿¡æ¯
            'question': self.clean_markdown_text(question_text),  # æ¸…ç†åçš„é¢˜ç›®æ–‡æœ¬
            'simple_answer': self.clean_markdown_text(simple_answer),  # æ¸…ç†åçš„ç²¾ç®€ç­”æ¡ˆæ–‡æœ¬
            'detailed_analysis': self.clean_markdown_text(detailed_analysis)  # æ¸…ç†åçš„è¯¦ç»†è§£ææ–‡æœ¬
        }
    
    # é¢„å¤„ç†æ–‡æœ¬ä»¥æé«˜è¯­éŸ³åˆæˆçš„å¯è¯»æ€§ï¼Œæ·»åŠ é€‚å½“çš„åœé¡¿
    # text: éœ€è¦é¢„å¤„ç†çš„æ–‡æœ¬
    # è¿”å›: é¢„å¤„ç†åçš„æ–‡æœ¬ï¼Œé€‚åˆè¯­éŸ³åˆæˆ
    def preprocess_text_for_speech(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬ä»¥æé«˜è¯­éŸ³å¯è¯»æ€§ï¼Œæ·»åŠ é€‚å½“çš„åœé¡¿"""
        # ç§»é™¤Markdownä»£ç å—ï¼ˆ```xxx```æ ¼å¼ï¼‰
        text = re.sub(r'\`\`\`[^`]*\`\`\`', '', text, flags=re.DOTALL)
        
        # ç§»é™¤è¡Œå†…ä»£ç ï¼ˆ`code`æ ¼å¼ï¼‰
        text = re.sub(r'`([^`]+)`', '', text)
        
        # ç§»é™¤Markdownåˆ—è¡¨ç¬¦å·ï¼ˆ-, *, +ï¼‰
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤ç¼–å·åˆ—è¡¨ç¬¦å·ï¼ˆ1. 2. ç­‰ï¼‰
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
        
        # ç§»é™¤å‰©ä½™çš„Markdownç¬¦å·ï¼ˆ# * _ ~ `ï¼‰
        text = re.sub(r'[#*_~`]', '', text)
        
        # æ›¿æ¢ç®­å¤´å’Œç‰¹æ®Šç¬¦å·ä¸ºä¸­æ–‡æè¿°å¹¶æ·»åŠ åœé¡¿
        text = re.sub(r'â†’', 'ï¼Œç„¶å', text)  # æ›¿æ¢å³ç®­å¤´ä¸º"ï¼Œç„¶å"
        text = re.sub(r'â†', 'ï¼Œè¿”å›', text)  # æ›¿æ¢å·¦ç®­å¤´ä¸º"ï¼Œè¿”å›"
        text = re.sub(r'â†‘', 'ï¼Œå‘ä¸Š', text)  # æ›¿æ¢ä¸Šç®­å¤´ä¸º"ï¼Œå‘ä¸Š"
        text = re.sub(r'â†“', 'ï¼Œå‘ä¸‹', text)  # æ›¿æ¢ä¸‹ç®­å¤´ä¸º"ï¼Œå‘ä¸‹"
        
        # åœ¨Vueç”Ÿå‘½å‘¨æœŸæ–¹æ³•å’ŒæŠ€æœ¯æœ¯è¯­ä¹‹é—´æ·»åŠ åœé¡¿
        lifecycle_methods = [
            'beforeCreate', 'created', 'beforeMount', 'mounted',
            'beforeUpdate', 'updated', 'beforeDestroy', 'destroyed',
            'beforeUnmount', 'unmounted', 'activated', 'deactivated'
        ]
        
        for method in lifecycle_methods:
            # åœ¨æ¯ä¸ªç”Ÿå‘½å‘¨æœŸæ–¹æ³•åæ·»åŠ åœé¡¿ï¼ˆä¸­æ–‡é€—å·ï¼‰
            text = re.sub(rf'\b{method}\b', f'{method}ï¼Œ', text)
        
        # åœ¨ç”±ç©ºæ ¼åˆ†éš”çš„ä»£ç å…ƒç´ ä¹‹é—´æ·»åŠ åœé¡¿
        text = re.sub(r'(\w+)\s+(\w+)\s+(\w+)', r'\1ï¼Œ\2ï¼Œ\3', text)
        
        # Add pauses around parentheses and brackets
        text = re.sub(r'\(', 'ï¼Œå¼€æ‹¬å·ï¼Œ', text)
        text = re.sub(r'\)', 'ï¼Œé—­æ‹¬å·ï¼Œ', text)
        text = re.sub(r'\[', 'ï¼Œå¼€æ–¹æ‹¬å·ï¼Œ', text)
        text = re.sub(r'\]', 'ï¼Œé—­æ–¹æ‹¬å·ï¼Œ', text)
        text = re.sub(r'\{', 'ï¼Œå¼€èŠ±æ‹¬å·ï¼Œ', text)
        text = re.sub(r'\}', 'ï¼Œé—­èŠ±æ‹¬å·ï¼Œ', text)
        
        # Add pauses around equals signs and operators
        text = re.sub(r'=', 'ï¼Œç­‰äºï¼Œ', text)
        text = re.sub(r'\+', 'ï¼ŒåŠ ï¼Œ', text)
        text = re.sub(r'\*', 'ï¼Œä¹˜ï¼Œ', text)
        text = re.sub(r'/', 'ï¼Œé™¤ï¼Œ', text)
        
        # Add pauses between camelCase words
        text = re.sub(r'([a-z])([A-Z])', r'\1ï¼Œ\2', text)
        
        # Add pauses around dots in method calls
        text = re.sub(r'\.', 'ï¼Œç‚¹ï¼Œ', text)
        
        # Clean up multiple consecutive commas
        text = re.sub(r'ï¼Œ+', 'ï¼Œ', text)
        
        # Ensure proper spacing around Chinese punctuation
        text = re.sub(r'ï¼Œ\s*ï¼Œ', 'ï¼Œ', text)
        text = re.sub(r'ï¼Œ\s*$', 'ã€‚', text)  # End with period instead of comma
        
        return text.strip()
    
    # å¼‚æ­¥æ–¹æ³•ï¼šä½¿ç”¨edge-ttsç”ŸæˆéŸ³é¢‘æ–‡ä»¶
    # text: è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬å†…å®¹
    # output_path: ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ä¿å­˜è·¯å¾„
    async def generate_audio(self, text: str, output_path: Path):
        """ä½¿ç”¨edge_tts 7.xä»æ–‡æœ¬ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        try:
            # é¢„å¤„ç†æ–‡æœ¬ä»¥æé«˜è¯­éŸ³å¯è¯»æ€§
            processed_text = self.preprocess_text_for_speech(text)
            
            # ä¸ºTTSåšé¢å¤–çš„æ–‡æœ¬æ¸…ç†
            # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼å’ŒåŸºæœ¬ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
            clean_text = re.sub(r'[^\w\s\u4e00-\u9fffï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š]', ' ', processed_text)
            clean_text = re.sub(r'\s+', ' ', clean_text)  # è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
            clean_text = clean_text.strip()
            
            # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œåˆ™è·³è¿‡å¤„ç†
            if not clean_text:
                print(f"Skipping empty text for {output_path}")
                return
            
            # åˆ›å»ºedge-ttsè¯­éŸ³ç®¡ç†å™¨
            voices_manager = await edge_tts.VoicesManager.create()
            
            # é¦–é€‰çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            preferred_voices = [
                "zh-CN-YunyangNeural",  # äº‘æ¨ï¼ˆç”·ï¼‰
                "zh-CN-YunjianNeural",  # äº‘å¥ï¼ˆç”·ï¼‰
                "zh-CN-YunxiNeural",    # äº‘æºªï¼ˆå¥³ï¼‰
                "zh-CN-YunhaoNeural",   # äº‘æµ©ï¼ˆç”·ï¼‰
                "zh-CN-YunzeNeural"     # äº‘æ³½ï¼ˆç”·ï¼‰
            ]
            
            selected_voice = None  # åˆå§‹åŒ–é€‰ä¸­çš„è¯­éŸ³ä¸ºNone
            all_voices = voices_manager.find()  # è·å–æ‰€æœ‰å¯ç”¨è¯­éŸ³
            
            print(f"Looking for voice from preferred list...")
            
            # å°è¯•ä»é¦–é€‰è¯­éŸ³åˆ—è¡¨ä¸­æ‰¾åˆ°å¯ç”¨çš„è¯­éŸ³
            for voice in preferred_voices:
                matching_voices = [v for v in all_voices if v["Name"] == voice]
                if matching_voices:
                    selected_voice = voice
                    print(f"âœ“ Found preferred voice: {selected_voice}")
                    break
                else:
                    print(f"âœ— Voice not available: {voice}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¦–é€‰è¯­éŸ³ï¼Œåˆ™æŸ¥æ‰¾ä»»ä½•ä¸­æ–‡(zh-CN)è¯­éŸ³ä½œä¸ºå¤‡é€‰
            if not selected_voice:
                print("No preferred voices found, looking for any zh-CN voice...")
                zh_cn_voices = [v for v in all_voices if v["Locale"].startswith("zh-CN")]
                if zh_cn_voices:
                    selected_voice = zh_cn_voices[0]["Name"]
                    print(f"âœ“ Using fallback zh-CN voice: {selected_voice}")
                    print(f"  Available zh-CN voices: {[v['Name'] for v in zh_cn_voices[:3]]}")
                else:
                    print("âš ï¸  No zh-CN voices found! This might cause issues.")
                    # åˆ—å‡ºå®é™…å¯ç”¨çš„è¯­è¨€åŒºåŸŸ
                    available_locales = list(set([v["Locale"] for v in all_voices]))
                    print(f"Available locales: {available_locales[:10]}")
                    selected_voice = "zh-CN-YunyangNeural"  # é»˜è®¤å¤‡é€‰è¯­éŸ³
            
            # ä½¿ç”¨edge-tts 7.xåˆ›å»ºTTSé€šä¿¡å¯¹è±¡
            communicate = edge_tts.Communicate(clean_text, selected_voice)
            
            # ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶
            await communicate.save(str(output_path))
            print(f"âœ“ Generated audio: {output_path.name}")
        except Exception as e:
            print(f"âœ— Error generating audio for {output_path}: {e}")
    
    # å¼‚æ­¥æ–¹æ³•ï¼šä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºç›®å½•ç»“æ„å’Œç›¸å…³æ–‡ä»¶
    # question_data: åŒ…å«é—®é¢˜ä¿¡æ¯çš„å­—å…¸
    # question_num: é—®é¢˜ç¼–å·
    async def create_question_directory(self, question_data: Dict[str, Any], question_num: int):
        """ä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºç›®å½•ç»“æ„å’Œç›¸å…³æ–‡ä»¶"""
        # è·å–é—®é¢˜IDï¼Œå¦‚æœæ²¡æœ‰IDåˆ™ä½¿ç”¨é—®é¢˜ç¼–å·
        question_id = question_data['metadata'].get('id', f'q{question_num:04d}')
        # æˆªå–IDçš„å‰8ä½å­—ç¬¦ï¼Œé¿å…æ–‡ä»¶åè¿‡é•¿
        id_prefix = str(question_id)[:8] if question_id else f'q{question_num:04d}'
        
        # åˆ›å»ºé—®é¢˜ç›®å½•ï¼Œä½¿ç”¨æ–°çš„å‘½åæ ¼å¼ q{ç¼–å·}_{IDå‰ç¼€}
        question_dir = self.output_dir / f"q{question_num:04d}_{id_prefix}"
        # åˆ›å»ºç›®å½•ï¼Œå¦‚æœçˆ¶ç›®å½•ä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™
        question_dir.mkdir(parents=True, exist_ok=True)
        
        # å®šä¹‰éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æ–°çš„å‘½åæ ¼å¼
        audio_simple_file = question_dir / f"q{question_num:04d}_{id_prefix}_audio_simple.mp3"  # ç®€å•ç­”æ¡ˆéŸ³é¢‘æ–‡ä»¶
        audio_question_file = question_dir / f"q{question_num:04d}_{id_prefix}_audio_question.mp3"  # é—®é¢˜éŸ³é¢‘æ–‡ä»¶
        audio_analysis_file = question_dir / f"q{question_num:04d}_{id_prefix}_audio_analysis.mp3"  # è¯¦ç»†è§£æéŸ³é¢‘æ–‡ä»¶
        
        # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        await self.generate_audio(question_data['simple_answer'], audio_simple_file)  # ç”Ÿæˆç®€å•ç­”æ¡ˆéŸ³é¢‘
        await self.generate_audio(question_data['question'], audio_question_file)  # ç”Ÿæˆé—®é¢˜éŸ³é¢‘
        await self.generate_audio(question_data['detailed_analysis'], audio_analysis_file)  # ç”Ÿæˆè¯¦ç»†è§£æéŸ³é¢‘
        
        # åˆ›å»ºmeta.jsonæ–‡ä»¶ï¼ŒåŒ…å«é—®é¢˜çš„æ‰€æœ‰å…ƒæ•°æ®å’Œå†…å®¹å­—ç¬¦ä¸²
        meta_data = {
            'id': question_data['metadata'].get('id', None),  # é—®é¢˜IDï¼Œä¼˜å…ˆä½¿ç”¨åŸå§‹æ–‡ä»¶ä¸­çš„UUIDï¼Œä¸ä½¿ç”¨question_numä½œä¸ºé»˜è®¤å€¼
            'type': question_data['metadata'].get('type', 'unknown'),  # é—®é¢˜ç±»å‹ï¼Œé»˜è®¤ä¸ºunknown
            'difficulty': question_data['metadata'].get('difficulty', 'medium'),  # éš¾åº¦çº§åˆ«ï¼Œé»˜è®¤ä¸ºmedium
            'tags': question_data['metadata'].get('tags', []),  # æ ‡ç­¾åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
            'question_length': len(question_data['question']),  # é—®é¢˜æ–‡æœ¬é•¿åº¦
            'simple_answer_length': len(question_data['simple_answer']),  # ç®€å•ç­”æ¡ˆæ–‡æœ¬é•¿åº¦
            'detailed_analysis_length': len(question_data['detailed_analysis']),  # è¯¦ç»†è§£ææ–‡æœ¬é•¿åº¦
            'created_at': None,  # åˆ›å»ºæ—¶é—´ï¼Œå¯ä»¥æ·»åŠ æ—¶é—´æˆ³
            # ç›´æ¥æ·»åŠ å†…å®¹å­—ç¬¦ä¸²ï¼Œä»¥æ–‡ä»¶åä½œä¸ºkey
            'question_markdown': question_data['question'],  # é—®é¢˜æ–‡æœ¬å†…å®¹
            'answer_simple_markdown': question_data['simple_answer'],  # ç®€å•ç­”æ¡ˆæ–‡æœ¬å†…å®¹
            'answer_analysis_markdown': question_data['detailed_analysis'],  # è¯¦ç»†è§£ææ–‡æœ¬å†…å®¹
            'files': {  # æ–‡ä»¶æ˜ å°„ï¼Œè®°å½•ç›¸å…³æ–‡ä»¶çš„è·¯å¾„ï¼ˆä½¿ç”¨æ–°çš„å‘½åæ ¼å¼ï¼‰
                'audio_simple': f'q{question_num:04d}_{id_prefix}_audio_simple.mp3',  # ç®€å•ç­”æ¡ˆéŸ³é¢‘æ–‡ä»¶
                'audio_question': f'q{question_num:04d}_{id_prefix}_audio_question.mp3',  # é—®é¢˜éŸ³é¢‘æ–‡ä»¶
                'audio_analysis': f'q{question_num:04d}_{id_prefix}_audio_analysis.mp3',  # è¯¦ç»†è§£æéŸ³é¢‘æ–‡ä»¶
                'meta': f'q{question_num:04d}_{id_prefix}_meta.json'  # å…ƒæ•°æ®æ–‡ä»¶æœ¬èº«çš„æ–‡ä»¶å
            }
        }
        
        # å®šä¹‰meta.jsonæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æ–°çš„å‘½åæ ¼å¼
        meta_file = question_dir / f"q{question_num:04d}_{id_prefix}_meta.json"
        # å†™å…¥meta.jsonæ–‡ä»¶ï¼Œä½¿ç”¨UTF-8ç¼–ç ï¼Œä¿ç•™ä¸­æ–‡å­—ç¬¦ä¸è¿›è¡ŒASCIIè½¬ä¹‰ï¼Œç¼©è¿›2ä¸ªç©ºæ ¼
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°åˆ›å»ºæˆåŠŸçš„ä¿¡æ¯
        print(f"âœ“ Created question directory: {question_dir}")
    
    # å¼‚æ­¥æ–¹æ³•ï¼šä¸»è¦å¤„ç†æ–¹æ³•ï¼Œç”¨äºè§£æmarkdownæ–‡ä»¶å¹¶ç”Ÿæˆé—®é¢˜ç›®å½•
    async def parse_and_generate(self):
        """è§£æmarkdownæ–‡ä»¶å¹¶ç”Ÿæˆé—®é¢˜ç›®å½•çš„ä¸»è¦æ–¹æ³•"""
        print(f"Reading markdown file: {self.input_file}")
        
        # è¯»å–è¾“å…¥çš„markdownæ–‡ä»¶
        with open(self.input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # å°†å†…å®¹åˆ†å‰²æˆé—®é¢˜å— - æ¯ä¸ªé—®é¢˜å—éƒ½ä»¥YAMLå‰ç½®å…ƒæ•°æ®å¼€å¤´
        # ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†å‰²ç­–ç•¥æ¥æ­£ç¡®å¤„ç†frontmatterå’Œå†…å®¹çš„ç»„åˆ
        import re
        
        # å¯»æ‰¾æ‰€æœ‰frontmatterå—çš„ä½ç½®ï¼ˆä»¥---å¼€å§‹çš„è¡Œï¼‰
        frontmatter_starts = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if line.strip() == '---':
                # æ£€æŸ¥è¿™æ˜¯å¦æ˜¯frontmatterçš„å¼€å§‹
                # å¯¹äºç¬¬ä¸€è¡Œæˆ–è€…åœ¨æ¥ä¸‹æ¥çš„å‡ è¡Œä¸­åŒ…å«id:/type:ç­‰å­—æ®µçš„æƒ…å†µ
                if i == 0:
                    frontmatter_starts.append(i)
                else:
                    # æ£€æŸ¥åé¢çš„å‡ è¡Œæ˜¯å¦åŒ…å« YAML å­—æ®µ
                    found_yaml_field = False
                    for check_line in range(i + 1, min(i + 5, len(lines))):
                        if any(keyword in lines[check_line] for keyword in ['id:', 'type:', 'difficulty:', 'tags:']):
                            found_yaml_field = True
                            break
                    if found_yaml_field:
                        frontmatter_starts.append(i)
        
        question_blocks = []  # ç”¨äºå­˜å‚¨å¤„ç†åçš„é—®é¢˜å—
        
        print(f"Found {len(frontmatter_starts)} frontmatter start positions: {frontmatter_starts[:5]}")
        
        # æ ¹æ®frontmatterä½ç½®åˆ†å‰²å†…å®¹
        for i, start_line in enumerate(frontmatter_starts):
            # ç¡®å®šå½“å‰å—çš„ç»“æŸä½ç½®
            if i + 1 < len(frontmatter_starts):
                end_line = frontmatter_starts[i + 1]
            else:
                end_line = len(lines)
            
            # æå–å½“å‰é—®é¢˜å—çš„æ‰€æœ‰è¡Œ
            block_lines = lines[start_line:end_line]
            block_content = '\n'.join(block_lines).strip()
            
            if block_content and 'é¢˜ç›®' in block_content:
                question_blocks.append(block_content)
                print(f"Added question block {len(question_blocks)} (first 50 chars): {block_content[:50]}...")
        
        print(f"Total question blocks found: {len(question_blocks)}")
        
        # è¿‡æ»¤æ‰ç©ºå—å’Œä¸åŒ…å«'é¢˜ç›®'çš„å—ï¼ˆå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„é—®é¢˜å—ï¼‰
        question_blocks = [block for block in question_blocks if block.strip() and 'é¢˜ç›®' in block]
        print(f"Filtered question blocks count: {len(question_blocks)}")
        
        # æ‰“å°æ‰¾åˆ°çš„é—®é¢˜å—æ•°é‡
        print(f"Found {len(question_blocks)} question blocks")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self.output_dir.mkdir(exist_ok=True)
        
        # å¤„ç†æ¯ä¸ªé—®é¢˜å—
        question_count = 0  # ç”¨äºè®°å½•æˆåŠŸå¤„ç†çš„é—®é¢˜æ•°é‡
        for i, block in enumerate(question_blocks):
            try:
                # è§£æé—®é¢˜å—
                question_data = self.parse_question_block(block)
                if question_data:
                    question_count += 1  # å¢åŠ æˆåŠŸå¤„ç†çš„é—®é¢˜è®¡æ•°
                    # ä¸ºè¿™ä¸ªé—®é¢˜åˆ›å»ºç›®å½•å’Œç›¸å…³æ–‡ä»¶
                    await self.create_question_directory(question_data, question_count)
                else:
                    print(f"Skipping invalid block {i+1}")
            except Exception as e:
                # æ•è·å¹¶æ‰“å°å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯
                print(f"âœ— Error processing block {i+1}: {e}")
        
        # æ‰“å°å¤„ç†ç»“æœç»Ÿè®¡ä¿¡æ¯
        print(f"\nâœ“ Successfully processed {question_count} questions")
        print(f"Output directory: {self.output_dir.absolute()}")
    
    # å¼‚æ­¥æ–¹æ³•ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³é€‰é¡¹
    async def list_available_voices(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³"""
        try:
            # åˆ›å»ºedge-ttsè¯­éŸ³ç®¡ç†å™¨
            voices_manager = await edge_tts.VoicesManager.create()
            # è·å–æ‰€æœ‰å¯ç”¨è¯­éŸ³
            all_voices = voices_manager.find()
            
            # è¿‡æ»¤å‡ºä¸­æ–‡è¯­éŸ³ï¼ˆè¯­è¨€åŒºåŸŸä»¥zhå¼€å¤´ï¼‰
            chinese_voices = [v for v in all_voices if v["Locale"].startswith("zh")]
            
            # æ‰“å°å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
            print("\n=== Available Chinese Voices ===")
            for voice in chinese_voices:
                print(f"Name: {voice['Name']}")  # è¯­éŸ³åç§°ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰
                print(f"  Locale: {voice['Locale']}")  # è¯­è¨€åŒºåŸŸ
                print(f"  Gender: {voice['Gender']}")  # æ€§åˆ«
                print(f"  Display Name: {voice['FriendlyName']}")  # æ˜¾ç¤ºåç§°ï¼ˆå‹å¥½åç§°ï¼‰
                print()
            
            print(f"Total Chinese voices found: {len(chinese_voices)}")
            return chinese_voices  # è¿”å›æ‰¾åˆ°çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
        except Exception as e:
            print(f"âœ— Error listing voices: {e}")  # æ‰“å°é”™è¯¯ä¿¡æ¯
            return []  # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›ç©ºåˆ—è¡¨

# ä¸»å‡½æ•°ï¼šç¨‹åºçš„å…¥å£é€»è¾‘
async def main():
    import sys  # å¯¼å…¥ç³»ç»Ÿæ¨¡å—ä»¥è·å–å‘½ä»¤è¡Œå‚æ•°
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—å‡ºè¯­éŸ³çš„å‘½ä»¤
    if len(sys.argv) == 2 and sys.argv[1] == "--list-voices":
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„è§£æå™¨å®ä¾‹ï¼ˆè¾“å…¥è¾“å‡ºè·¯å¾„ä¸é‡è¦ï¼‰
        parser = MarkdownQuestionParser("", "")
        # è°ƒç”¨åˆ—å‡ºè¯­éŸ³çš„æ–¹æ³•
        await parser.list_available_voices()
        return  # å®Œæˆåè¿”å›ï¼Œä¸æ‰§è¡Œåç»­ä»£ç 
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°æ˜¯å¦æ­£ç¡®
    if len(sys.argv) != 3:
        # æ‰“å°ä½¿ç”¨è¯´æ˜
        print("Usage: python3 question_to_speech.py <input_markdown_file> <output_directory>")
        print("       python3 question_to_speech.py --list-voices")
        print("Example: python3 question_to_speech.py vue_questions.md format-output")
        sys.exit(1)  # é€€å‡ºç¨‹åºï¼Œè¿”å›é”™è¯¯ç 1
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    input_file = sys.argv[1]  # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯è¾“å…¥markdownæ–‡ä»¶è·¯å¾„
    output_dir = sys.argv[2]  # ç¬¬äºŒä¸ªå‚æ•°æ˜¯è¾“å‡ºç›®å½•è·¯å¾„
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"âœ— Error: Input file '{input_file}' does not exist.")
        sys.exit(1)  # é€€å‡ºç¨‹åºï¼Œè¿”å›é”™è¯¯ç 1
    
    # åˆ›å»ºè§£æå™¨å®ä¾‹å¹¶æ‰§è¡Œå¤„ç†
    parser = MarkdownQuestionParser(input_file, output_dir)
    await parser.parse_and_generate()

# ç¨‹åºå…¥å£ç‚¹ï¼šå½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶æ‰§è¡Œ
if __name__ == "__main__":
    # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥çš„mainå‡½æ•°
    asyncio.run(main())
